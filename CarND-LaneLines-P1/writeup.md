#Finding Lane Lines on the Road#

The goals of this project were the following:
* Make an image processing pipeline that finds lane lines on a series of example images and video files that are representative of that which would be found on a real vehicle
* Reflect on the performance of the pipeline and suggest possible improvements

---

### Reflection

###1. Pipeline Description

The pipeline employed for this project consisted of 6 steps with the output of one step being the input for subsequent steps. The description of each step is as follows:

- First, we take the raw image and convert it to grayscale. This is done to support the Canny edge detection performed further down the pipeline.
- Second, the grayscale image is passed through a Gaussian filter. This was done to perform additional smoothing of the image before performing edge detection in hopes of minimizing the number of small edges found. Kernel size of the filter was subjectively hand-tuned. This pipeline step seemed to have a minor effect on the outcome and could potentially be removed with little consequence.
- Third, the filtered image is passed to the Canny edge detector. The upper and lower thresholds for edge detection were again subjectively hand-tuned. 
- Fourth, we applied a region-of-interest mask to the edges found in the previous step. The defined region was a triangle with points at the lower left and right corners of the image and an apex point laterally centered at the approximate horizon. The intent here was to remove extraneous edges that are not directly determined to be lane lines. We discuss potential issues with this fixed image mask below.
- Fifth we take the masked edge image and pass it to a Hough transform to consolidate the edges to a set of lines representing the left and right lane lines. Initially the given draw_lines helper function was used to draw the lane lines, but the hough_lines helper function signature was modified such that we could pass in the draw_lines2 function to draw single left and right lane lines. The draw_lines2 function draws only two lines - one for the left lane line and one for the right. It does this by first examining the lines determined from the Hough transform and grouping them by slope - negative slope for the left lane line and positive slope for the right. For the two groups we then fit a first-order polynomial (using the numpy polyfit function) through the points that define each line in the group.  This gives us an equation that we can then use to draw the lane line. We define the lower bound for each line to be lower edge of the image and the upper bound to be the y-value of the apex point defined above. Plugging these values into our equations then gives us the lateral position of each line endpoint which then allows each lane line to be drawn.
- Sixth, and finally, we take the two lane lines as drawn in the previous step and overlay them on the original image. 

###2. Identify potential shortcomings with your current pipeline

While the pipeline employed for this project performed sufficiently, there are several issues or simplifications that would most likely prevent it from being used in the general case. First, when masking the image to define region of interest we define a fixed polygon. This polygon is defined as a triangle with two points of the triangle being the lower left and right corners of the image connected to the third point, the apex, which is defined roughly as the geometric center of the image. The intent of this masking was to prevent any edges found above the horizon and to the sides of the road from being considered when performing the Hough transform. This fixed polygon works well when the vehicle travels on a straight and level road. However, the location of the horizon will undoubtedly move up and down in the camera view as the vehicle travels down and up hills. Likewise, as the road curves the apex would ideally move with the curve and also be different for left and right lane lines. Being able to dynamically move the apex position to correct for horizon and left and right curves would definitely improve the pipeline. Another issue arises when we again considered curves in the road. The draw_lines2 function grouped potential lane lines according to their slope, assuming that left lane lines would have negative slope and right lane lines positive slope. When the road curves, however this simple classification no longer holds as the lane lines turn back on themselves and have both positive and negative slope. That said, approximating a curved lane line with a single straight line is already a difficult task, and the appropriateness of which very much depends on how the lane lines will be used to control the vehicle. Also, as performance on the challenge problem revealed, the algorithm did not perform as well as hoped when encountering variable lighting conditions and faded lane line markings. One potential addition to the pipeline that could address these issues might be to add an extra step to dynamically adjust contrast levels in the images in an attempt to force the lane markings to "pop" in the image. Another possibility would be to add line smoothing, interpolation, or filtering between frames of the video feed in order to ignore potential anomolies in single frames. Thinking more broadly beyond just the challenge problem, one could also imagine this pipeline having issues with multiple lane lines on the road, which might easily occur when driving through a construction zone, and cases where the lane lines are completely are partially obscured because of adverse weather, particularly snow. In these instances we could again interpolate between frames to guess the location of the lane line. If the lane line is completely obscured for long stretches we would need to find an alternative method altogether to center the vehicle in the lane. This does not seem at all unreasonable because that is exactly what a human driver would do under similar circumstances.  


###3. Suggest possible improvements to your pipeline

Beyond the issues and suggested fixes listed above, there are several practical improvements that could be made to the pipeline. First, almost all parameters were hand-tuned and are most likely not optimal. It would be extremely beneficial to develop some sort of machine learning or optimization pipeline to find a set of optimal parameters for each of the individual pipeline stages. Second, the line drawing, at times, was not smooth frame-to-frame. If these lane lines are being used in some sort of control algorithm, this "noisy" movement of the lines would most-likely need to be accounted for. As mentioned above, applying some sort of smoothing algorithm between frames could potentially help this. Finally, based on performance, the pipeline, as-is, would not be applicable in a real-time use-case since the processing times for each video were greater than the lengths of the videos themselves. Porting the implementation to a native language, such as C++, could potentially resolve this issue.

